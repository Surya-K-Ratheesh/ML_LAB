{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU, PReLU, ELU\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the features and target variable\n",
    "X = dataset.iloc[:, 3:-1]  # Selecting features from 3rd column to second-last\n",
    "y = dataset.iloc[:, -1]  # Selecting the target variable (last column)\n",
    "\n",
    "# Display the first 5 rows of the features\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding categorical variables 'Geography' and 'Gender'\n",
    "geography = pd.get_dummies(X[\"Geography\"], drop_first=True)\n",
    "gender = pd.get_dummies(X['Gender'], drop_first=True)\n",
    "\n",
    "# Concatenating the encoded variables to the dataset\n",
    "X = pd.concat([X, geography, gender], axis=1)\n",
    "\n",
    "# Dropping original 'Geography' and 'Gender' columns\n",
    "X.drop(['Geography', 'Gender'], axis=1, inplace=True)\n",
    "\n",
    "# Display the first 5 rows after preprocessing\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Standardizing the feature variables\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Artificial Neural Network (ANN) model\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer='he_uniform', activation='relu', input_dim=11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer='he_uniform', activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "\n",
    "# Summarize the model\n",
    "classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model_history = classifier.fit(X_train, y_train, validation_split=0.33, batch_size=10, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Converting probabilities into binary predictions\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Displaying the predicted values\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model performance\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'The accuracy of the model is {accuracy}')\n",
    "\n",
    "cl_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\\n\", cl_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model accuracy over epochs\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model loss over epochs\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing final training and validation loss\n",
    "final_training_loss = model_history.history['loss'][-1]\n",
    "final_validation_loss = model_history.history['val_loss'][-1]\n",
    "print(f\"Final training loss: {final_training_loss}\")\n",
    "print(f\"Final validation loss: {final_validation_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
